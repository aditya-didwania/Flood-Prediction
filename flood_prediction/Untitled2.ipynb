{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "    global labelencoder_X_1,labelencoder_X_2,labelencoder_X_3,onehotencoder,sc_X\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    dataset = pd.read_csv('updated_test.csv')\n",
    "    dataset = dataset[ dataset['YEAR']>1980 ]\n",
    "    dataset = dataset.dropna()\n",
    "    X = dataset.iloc[:,[0,3,4,6,7]].values\n",
    "    y = dataset.iloc[:,5].values\n",
    "    '''print(\"X:\")\n",
    "    print(X[2369:2375][:])\n",
    "    print(\"\\nY:\")\n",
    "    print(y[2369:2375][:'''\n",
    "    from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "    labelencoder_X_1 = LabelEncoder()\n",
    "    \n",
    "    X[:, 0] = labelencoder_X_1.fit_transform(X[:, 0])\n",
    "   \n",
    "    #print(X[3580][:])\n",
    "    X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "    #print(X[3580][:])\n",
    "    X[:, 3] = labelencoder_X_1.fit_transform(X[:, 3])\n",
    "    #print(X[3580][:])\n",
    "    X[:, 4] = labelencoder_X_1.fit_transform(X[:, 4])\n",
    "    #print(X[3580][:])\n",
    "    #print(X.shape)\n",
    "    #print(\"X labelencoded:\")\n",
    "    #print(X[2369:2375][:])\n",
    "    onehotencoder = OneHotEncoder(categorical_features = [0,1,3])\n",
    "    X = onehotencoder.fit_transform(X).toarray()\n",
    "    #print(X.shape)\n",
    "    X = X[:,1:]\n",
    "    #print(\"X OneHotEncoded:\")\n",
    "    #print(X[2369][:])\n",
    "    labelencoder_y = LabelEncoder()\n",
    "    y = labelencoder_y.fit_transform(y)\n",
    "    #print(\"\\nY labelencoded:\")\n",
    "    #print(y[2369:2375][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=['TAMIL NADU', 'Mar-May', '413.09999999999997' ,'Hilly/coastal' ,'humid']\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "print(x)\n",
    "#preprocessing x\n",
    "x = np.reshape(x,(-1,5))\n",
    "x[:, 0] = labelencoder_X_1.transform(x[:, 0])\n",
    "x[:, 1] = labelencoder_X_1.transform(x[:, 1])\n",
    "x[:, 3] = labelencoder_X_1.transform(x[:, 3])\n",
    "x[:, 4] = labelencoder_X_1.transform(x[:, 4])\n",
    "print(x)\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0,1,3,4])\n",
    "x = onehotencoder.transform(x).toarray()\n",
    "sc_X = StandardScaler()\n",
    "x = x[:,1:]\n",
    "x = sc_X.transform(x)\n",
    "#print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " X Train\t\t\t X Test\n",
      "(3349, 47)\t\t\t(838, 47)\n",
      "\n",
      " Y Train\t\t\t Y Test\n",
      " (3349,)\t\t\t (838,)\n",
      "\n",
      "\n",
      "\n",
      "X Train normalized:\n",
      "[-0.18686801 -0.18857274 -0.17270726 -0.1790232  -0.19443768 -0.18167091\n",
      " -0.18254602 -0.19277761 -0.18254602 -0.18686801 -0.19026428 -0.19026428\n",
      " -0.18601059 -0.18167091 -0.18428537 -0.18601059 -0.18772205  5.30299341\n",
      " -0.18514972 -0.18857274 -0.18601059 -0.18428537 -0.18942014 -0.18772205\n",
      " -0.18514972 -0.18601059 -0.18254602 -0.18686801 -0.18167091 -0.5671207\n",
      " -0.5786145  -0.5818326   1.7187074  -0.50335699 -0.18686801 -0.27345082\n",
      " -0.19026428 -0.18254602 -0.18428537  1.53155292 -0.18772205 -0.18514972\n",
      " -0.18341749 -0.4423171  -0.18254602 -0.48689297 -0.13585936]\n",
      "\n",
      "X Test normalized:\n",
      "[-0.18686801 -0.18857274 -0.17270726 -0.1790232  -0.19443768 -0.18167091\n",
      " -0.18254602 -0.19277761 -0.18254602 -0.18686801 -0.19026428  5.25584737\n",
      " -0.18601059 -0.18167091 -0.18428537 -0.18601059 -0.18772205 -0.18857274\n",
      " -0.18514972 -0.18857274 -0.18601059 -0.18428537 -0.18942014 -0.18772205\n",
      " -0.18514972 -0.18601059 -0.18254602 -0.18686801 -0.18167091  1.76329307\n",
      " -0.5786145  -0.5818326  -0.5818326  -0.50335699 -0.18686801 -0.27345082\n",
      " -0.19026428 -0.18254602 -0.18428537 -0.65293206 -0.18772205 -0.18514972\n",
      " -0.18341749  2.2608215  -0.18254602 -0.6086652  -1.09172701]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state = 0)\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "print(\"\\n X Train\\t\\t\\t X Test\")\n",
    "print(str(X_train.shape)+\"\\t\\t\\t\"+str(X_test.shape))\n",
    "print(\"\\n Y Train\\t\\t\\t Y Test\")\n",
    "print(\" \"+str(y_train.shape)+\"\\t\\t\\t \"+str(y_test.shape))\n",
    "print()\n",
    "print()\n",
    "y_train = np.reshape(y_train,(-1,1))\n",
    "y_train = onehotencoder.fit_transform(y_train).toarray()\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#normalization\n",
    "#val-mean/n\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "print(\"\\nX Train normalized:\")\n",
    "print(X_train[1][:])\n",
    "print(\"\\nX Test normalized:\")\n",
    "print(X_test[1][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
