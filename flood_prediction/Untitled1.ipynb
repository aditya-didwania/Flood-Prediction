{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load models from file\n",
    "def load_all_models(n_models):\n",
    "\tall_models = list()\n",
    "\tfor i in range(n_models):\n",
    "\t\t# define filename for this ensemble\n",
    "\t\tfilename = 'main_models/model_' + str(i + 1) + '.h5'\n",
    "\t\t# load model from file\n",
    "\t\tmodel = load_model(filename)\n",
    "\t\t# add to list of members\n",
    "\t\tall_models.append(model)\n",
    "\t\tprint('>loaded %s' % filename)\n",
    "\treturn all_models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stacked model input dataset as outputs from the ensemble\n",
    "def stacked_dataset(members, inputX):\n",
    "    print(\"stacked_data\")\n",
    "    print(inputX.shape)\n",
    "    stackX = None\n",
    "    for model in members:\n",
    "        # make prediction\n",
    "        yhat = model.predict(inputX, verbose=0)\n",
    "        # stack predictions into [rows, members, probabilities]\n",
    "        if stackX is None:\n",
    "            stackX = yhat\n",
    "        else:\n",
    "            stackX = dstack((stackX, yhat))\n",
    "    # flatten predictions to [rows, members x probabilities]\n",
    "    print(stackX.shape)\n",
    "    stackX = stackX.reshape((stackX.shape[0], stackX.shape[1]*stackX.shape[2]))\n",
    "    print(stackX)\n",
    "    return stackX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# fit a model based on the outputs from the ensemble members\n",
    "def fit_stacked_model(members, inputX, inputy):\n",
    "    # create dataset using ensemble\n",
    "    print(\"fit_stacked_model\")\n",
    "    print(inputX.shape)\n",
    "    stackedX = stacked_dataset(members, inputX)\n",
    "    # fit standalone model\n",
    "    model = svm.SVC(kernel='linear')\n",
    "    model.fit(stackedX, inputy)\n",
    "    return model\n",
    "def stacked_prediction(members, model, inputX):\n",
    "    # create dataset using ensemble\n",
    "    print(\"stacked_pred\")\n",
    "    print(inputX.shape)\n",
    "    stackedX = stacked_dataset(members, inputX)\n",
    "    print(\"stackedX\",stackedX.shape)\n",
    "    # make a prediction\n",
    "    yhat = model.predict(stackedX)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4187, 5)\n",
      "(4187, 5)\n",
      "(4187, 48)\n",
      "(4187, 47)\n",
      "(4187, 47)\n",
      "(4187, 47)\n",
      "x train (3349, 47)\n",
      "x test (838, 47)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from numpy import dstack\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import tensorflow as tf\n",
    "dataset = pd.read_csv('updated_test.csv')\n",
    "dataset = dataset[ dataset['YEAR']>1980 ]\n",
    "dataset = dataset.dropna()\n",
    "X = dataset.iloc[:,[0,3,4,6,7]].values\n",
    "y = dataset.iloc[:,5].values\n",
    "print(X.shape)\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "X[:, 0] = labelencoder_X.fit_transform(X[:, 0])\n",
    "X[:, 1] = labelencoder_X.fit_transform(X[:, 1])\n",
    "X[:, 3] = labelencoder_X.fit_transform(X[:, 3])\n",
    "X[:, 4] = labelencoder_X.fit_transform(X[:, 4])\n",
    "print(X.shape)\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0,1,3])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "print(X.shape)\n",
    "\n",
    "X = X[:,1:]\n",
    "print(X.shape)\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state = 0)\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "y_train = np.reshape(y_train,(-1,1))\n",
    "y_train = onehotencoder.fit_transform(y_train).toarray()\n",
    "print(X.shape)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#normalization\n",
    "#val-mean/n\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "print(X.shape)\n",
    "print(\"x train\",X_train.shape)\n",
    "print(\"x test\",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">loaded main_models/model_1.h5\n",
      ">loaded main_models/model_2.h5\n",
      ">loaded main_models/model_3.h5\n",
      ">loaded main_models/model_4.h5\n",
      ">loaded main_models/model_5.h5\n",
      "Loaded 5 models\n",
      "y test (838,)\n",
      "x test (838, 47)\n",
      "y test enc (838, 6)\n",
      "Model Accuracy: 0.947\n",
      "y test enc (838, 6)\n",
      "Model Accuracy: 0.942\n",
      "y test enc (838, 6)\n",
      "Model Accuracy: 0.947\n",
      "y test enc (838, 6)\n",
      "Model Accuracy: 0.945\n",
      "y test enc (838, 6)\n",
      "Model Accuracy: 0.945\n",
      "fit_stacked_model\n",
      "(838, 47)\n",
      "stacked_data\n",
      "(838, 47)\n",
      "(838, 6, 5)\n",
      "[[1.0000000e+00 1.0000000e+00 1.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 1.0000000e+00 1.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 1.0000000e+00 1.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " ...\n",
      " [1.0000000e+00 1.0000000e+00 1.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [3.3324632e-01 2.0566601e-01 2.5782811e-02 ... 2.0181219e-35\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 1.0000000e+00 1.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]]\n",
      "(838, 47)\n",
      "stacked_pred\n",
      "(838, 47)\n",
      "stacked_data\n",
      "(838, 47)\n",
      "(838, 6, 5)\n",
      "[[1.0000000e+00 1.0000000e+00 1.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 1.0000000e+00 1.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 1.0000000e+00 1.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " ...\n",
      " [1.0000000e+00 1.0000000e+00 1.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [3.3324632e-01 2.0566601e-01 2.5782811e-02 ... 2.0181219e-35\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 1.0000000e+00 1.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]]\n",
      "stackedX (838, 30)\n",
      "Stacked Test Accuracy: 0.950\n"
     ]
    }
   ],
   "source": [
    "n_members = 5\n",
    "members = load_all_models(n_members)\n",
    "print('Loaded %d models' % len(members))\n",
    "# evaluate standalone models on test dataset\n",
    "print(\"y test\",y_test.shape)\n",
    "print(\"x test\",X_test.shape)\n",
    "for model in members:\n",
    "    testy_enc = to_categorical(y_test)\n",
    "    print(\"y test enc\",testy_enc.shape)\n",
    "    _, acc = model.evaluate(X_test, testy_enc, verbose=0)\n",
    "    print('Model Accuracy: %.3f' % acc)\n",
    "# fit stacked model using the ensemble\n",
    "model = fit_stacked_model(members, X_test, y_test)\n",
    "print(X_test.shape)\n",
    "# evaluate model on test set\n",
    "yhat = stacked_prediction(members, model, X_test)\n",
    "acc = accuracy_score(y_test, yhat)\n",
    "print('Stacked Test Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'jan'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\aksha\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'jan'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-c676ea485848>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mgiven_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRainfallData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'STATE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'KL'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mRainfallData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRainfallData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgiven_state\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRainfallData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'jan'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\aksha\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2994\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2995\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2996\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\aksha\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'jan'"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jun-Sep TAMIL NADU Hilly/coastal\n"
     ]
    }
   ],
   "source": [
    "    month='06'\n",
    "    state=\"TN\"\n",
    "    if(month == '01' or month == '02'):\n",
    "        month = 'Jan-Feb'\n",
    "        duration = 2\n",
    "    elif(month == '03' or month == '04' or month == '05'):\n",
    "        month = 'Mar-May'\n",
    "        duration = 3\n",
    "    elif(month == '06' or month == '07' or month == '08' or month == '09'):\n",
    "        month = 'Jun-Sep'\n",
    "        duration = 4\n",
    "    elif(month == '10' or month == '11' or month == '12'):\n",
    "        month = 'Oct-Dec'\n",
    "        duration = 3\n",
    "\n",
    "    #for the state code\n",
    "    if(state == 'WB'):\n",
    "        state = 'GANGETIC WEST BENGAL'\n",
    "    elif(state == 'AN'):\n",
    "        state = 'ANDAMAN & NICOBAR ISLANDS'\n",
    "    elif(state == 'AR'):\n",
    "        state = 'ARUNACHAL PRADESH'\n",
    "    elif(state == 'AS'):\n",
    "        state = 'ASSAM & MEGHALAYA'\n",
    "    elif(state == 'BR'):\n",
    "        state = 'BIHAR'\n",
    "    elif(state == 'CG'):\n",
    "        state = 'CHATTISGARH'\n",
    "    elif(state == 'AD'):\n",
    "        state = 'COASTAL ANDHRA PRADESH'\n",
    "    elif(state == 'KA'):\n",
    "        state = 'COASTAL KARNATAKA'\n",
    "    elif(state == 'MP'):\n",
    "        state = 'EAST MADHYA PRADESH'\n",
    "    elif(state == 'RJ'):\n",
    "        state = 'EAST RAJASTHAN'\n",
    "    elif(state == 'UP'):\n",
    "        state = 'EAST UTTAR PRADESH'\n",
    "    elif(state == 'GJ'):\n",
    "        state = 'GUJARAT REGION'\n",
    "    elif(state == 'DL'):\n",
    "        state = 'HARYANA DELHI & CHANDIGARH'\n",
    "    elif(state == 'HP'):\n",
    "        state = 'HIMACHAL PRADESH'\n",
    "    elif(state == 'JK'):\n",
    "        state = 'JAMMU & KASHMIR'\n",
    "    elif(state == 'JH'):\n",
    "        state = 'JHARKHAND'\n",
    "    elif(state == 'KL'):\n",
    "        state = 'KERALA'\n",
    "    elif(state == 'GA'):\n",
    "        state = 'KONKAN & GOA'\n",
    "    elif(state == 'LD'):\n",
    "        state = 'LAKSHWADEEP'\n",
    "    elif(state == 'MH'):\n",
    "        state = 'MADHYA MAHARASHTRA'\n",
    "    elif(state == 'MT'):\n",
    "        state = 'MATATHWADA'\n",
    "    elif(state == 'MN'):\n",
    "        state = 'NAGA MANI MIZO TRIPURA'\n",
    "    elif(state == 'KA'):\n",
    "        state = 'NORTH INTERIOR KARNATAKA'\n",
    "    elif(state == 'OD'):\n",
    "        state = 'ORISSA'\n",
    "    elif(state == 'PB'):\n",
    "        state = 'PUNJAB'\n",
    "    elif(state == 'RS'):\n",
    "        state = 'RAYALSEEMA'\n",
    "    elif(state == 'SK'):\n",
    "        state = 'SAURASHTRA & KUTCH'\n",
    "    elif(state == 'KA'):\n",
    "        state = 'SOUTH INTERIOR KARNATAKA'\n",
    "    elif(state == 'SK'):\n",
    "        state = 'SUB HIMALAYAN WEST BENGAL & SIKKIM'\n",
    "    elif(state == 'TN'):\n",
    "        state = 'TAMIL NADU'\n",
    "    elif(state == 'TS'):\n",
    "        state = 'TELANGANA'\n",
    "    elif(state == 'UK'):\n",
    "        state = 'UTTARAKHAND'\n",
    "    elif(state == 'VD'):\n",
    "        state = 'VIDARBHA'\n",
    "    elif(state == 'MP'):\n",
    "        state = 'WEST MADHYA PRADESH'\n",
    "    elif(state == 'RJ'):\n",
    "        state = 'WEST RAJASTHAN'\n",
    "    elif(state == 'UP'):\n",
    "        state = 'WEST UTTAR PRADESH'\n",
    "\n",
    "    #for the terrain\n",
    "    if(state == 'GANGETIC WEST BENGAL'):\n",
    "        terrain = 'Coastal-plateau'\n",
    "    elif(state == 'ANDAMAN & NICOBAR ISLANDS'):\n",
    "        terrain = 'Island'\n",
    "    elif(state == 'ARUNACHAL PRADESH'):\n",
    "        terrain = 'Hilly'\n",
    "    elif(state == 'ASSAM & MEGHALAYA'):\n",
    "        terrain = 'Hilly'\n",
    "    elif(state == 'BIHAR'):\n",
    "        terrain = 'Plain-land'\n",
    "    elif(state == 'CHATTISGARH'):\n",
    "        terrain = 'Hilly'\n",
    "    elif(state == 'COASTAL ANDHRA PRADESH'):\n",
    "        terrain = 'Coastal'\n",
    "    elif(state == 'COASTAL KARNATAKA'):\n",
    "        terrain = 'Coastal'\n",
    "    elif(state == 'EAST MADHYA PRADESH'):\n",
    "        terrain = 'Everything'\n",
    "    elif(state == 'EAST RAJASTHAN'):\n",
    "        terrain = 'Desert'\n",
    "    elif(state == 'EAST UTTAR PRADESH'):\n",
    "        terrain = 'Rugged'\n",
    "    elif(state == 'GUJARAT REGION'):\n",
    "        terrain = 'Desert/marsh'\n",
    "    elif(state == 'HARYANA DELHI & CHANDIGARH'):\n",
    "        terrain = 'Plain-land'\n",
    "    elif(state == 'HIMACHAL PRADESH'):\n",
    "        terrain = 'Hilly'\n",
    "    elif(state == 'JAMMU & KASHMIR'):\n",
    "        terrain = 'Hilly'\n",
    "    elif(state == 'JHARKHAND'):\n",
    "        terrain = 'Forest'\n",
    "    elif(state == 'KERALA'):\n",
    "        terrain = 'Coastal'\n",
    "    elif(state == 'KONKAN & GOA'):\n",
    "        terrain = 'Hilly/coastal'\n",
    "    elif(state == 'LAKSHWADEEP'):\n",
    "        terrain = 'Island'\n",
    "    elif(state == 'MADHYA MAHARASHTRA'):\n",
    "        terrain = 'Plain-land'\n",
    "    elif(state == 'MATATHWADA'):\n",
    "        terrain = 'Barren'\n",
    "    elif(state == 'NAGA MANI MIZO TRIPURA'):\n",
    "        terrain = 'Hilly'\n",
    "    elif(state == 'NORTH INTERIOR KARNATAKA'):\n",
    "        terrain = 'Coastal'\n",
    "    elif(state == 'ORISSA'):\n",
    "        terrain = 'Coastal'\n",
    "    elif(state == 'PUNJAB'):\n",
    "        terrain = 'Plain-land'\n",
    "    elif(state == 'RAYALSEEMA'):\n",
    "        terrain = 'Plain-land'\n",
    "    elif(state == 'SAURASHTRA & KUTCH'):\n",
    "        terrain = 'Hilly'\n",
    "    elif(state == 'SOUTH INTERIOR KARNATAKA'):\n",
    "        terrain = 'Coastal'\n",
    "    elif(state == 'SUB HIMALAYAN WEST BENGAL & SIKKIM'):\n",
    "        terrain = 'Hilly'\n",
    "    elif(state == 'TAMIL NADU'):\n",
    "        terrain = 'Hilly/coastal'\n",
    "    elif(state == 'TELANGANA'):\n",
    "        terrain = 'Hilly/plain'\n",
    "    elif(state == 'UTTARAKHAND'):\n",
    "        terrain = 'Hilly'\n",
    "    elif(state == 'VIDARBHA'):\n",
    "        terrain = 'Plain-land'\n",
    "    elif(state == 'WEST MADHYA PRADESH'):\n",
    "        terrain = 'Plain-land'\n",
    "    elif(state == 'WEST RAJASTHAN'):\n",
    "        terrain = 'Desert'\n",
    "    elif(state == 'WEST UTTAR PRADESH'):\n",
    "        terrain = 'Hilly'\n",
    "    print(month,state,terrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "RainfallData = pd.read_csv('RainfallData.csv')\n",
    "given_state = RainfallData['STATE']=='TN'\n",
    "RainfallData = RainfallData[given_state]\n",
    "prec = RainfallData[month].iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TAMIL NADU' 'Jun-Sep' '330.840625' 'Hilly/coastal' 'humid']\n"
     ]
    }
   ],
   "source": [
    "x = np.array([state,month,prec,terrain,'humid']);\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['TAMIL NADU' 'Jun-Sep' '330.840625' 'Hilly/coastal' 'humid']]\n"
     ]
    }
   ],
   "source": [
    "x=np.reshape(x,(-1,5))\n",
    "print(x)\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_x = LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n",
      "(1, 5)\n"
     ]
    }
   ],
   "source": [
    "x[:,0] = labelencoder_x.fit_transform(x[:, 0])\n",
    "x[:, 1] = labelencoder_x.fit_transform(x[:, 1])\n",
    "x[:, 3] = labelencoder_x.fit_transform(x[:, 3])\n",
    "x[:, 4] = labelencoder_x.fit_transform(x[:, 4])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0,1,3])\n",
    "print(x.shape)\n",
    "x= onehotencoder.fit_transform(x).toarray()\n",
    "print(x.shape)\n",
    "x = x[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#normalization\n",
    "#val-mean/n\n",
    "sc_X = StandardScaler()\n",
    "x = sc_X.fit_transform(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
